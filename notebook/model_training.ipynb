{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271c9d28",
   "metadata": {},
   "source": [
    "# Machine Learning Model Training and Evaluation\n",
    "\n",
    "This notebook implements multiple regression models and evaluates their performance using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e078ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25745a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows of the dataset:\n",
      "   gender race_ethnicity parental_level_of_education         lunch  \\\n",
      "0  female        group B           bachelor's degree      standard   \n",
      "1  female        group C                some college      standard   \n",
      "2  female        group B             master's degree      standard   \n",
      "3    male        group A          associate's degree  free/reduced   \n",
      "4    male        group C                some college      standard   \n",
      "\n",
      "  test_preparation_course  math_score  reading_score  writing_score  \n",
      "0                    none          72             72             74  \n",
      "1               completed          69             90             88  \n",
      "2                    none          90             95             93  \n",
      "3                    none          47             57             44  \n",
      "4                    none          76             78             75  \n",
      "\n",
      "Columns in the dataset:\n",
      "['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course', 'math_score', 'reading_score', 'writing_score']\n",
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gender                       1000 non-null   object\n",
      " 1   race_ethnicity               1000 non-null   object\n",
      " 2   parental_level_of_education  1000 non-null   object\n",
      " 3   lunch                        1000 non-null   object\n",
      " 4   test_preparation_course      1000 non-null   object\n",
      " 5   math_score                   1000 non-null   int64 \n",
      " 6   reading_score                1000 non-null   int64 \n",
      " 7   writing_score                1000 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load and examine the data\n",
    "df = pd.read_csv(\"stud.csv\")\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nColumns in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nDataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cbd9b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows with total score:\n",
      "   gender race_ethnicity parental_level_of_education         lunch  \\\n",
      "0  female        group B           bachelor's degree      standard   \n",
      "1  female        group C                some college      standard   \n",
      "2  female        group B             master's degree      standard   \n",
      "3    male        group A          associate's degree  free/reduced   \n",
      "4    male        group C                some college      standard   \n",
      "\n",
      "  test_preparation_course  math_score  reading_score  writing_score  \\\n",
      "0                    none          72             72             74   \n",
      "1               completed          69             90             88   \n",
      "2                    none          90             95             93   \n",
      "3                    none          47             57             44   \n",
      "4                    none          76             78             75   \n",
      "\n",
      "   total_score  \n",
      "0          218  \n",
      "1          247  \n",
      "2          278  \n",
      "3          148  \n",
      "4          229  \n",
      "\n",
      "Summary statistics of total score:\n",
      "count    1000.000000\n",
      "mean      203.312000\n",
      "std        42.771978\n",
      "min        27.000000\n",
      "25%       175.000000\n",
      "50%       205.000000\n",
      "75%       233.000000\n",
      "max       300.000000\n",
      "Name: total_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create total score by combining math, reading, and writing scores\n",
    "df['total_score'] = df['math_score'] + df['reading_score'] + df['writing_score']\n",
    "\n",
    "print(\"\\nFirst few rows with total score:\")\n",
    "print(df.head())\n",
    "print(\"\\nSummary statistics of total score:\")\n",
    "print(df['total_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6a5a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "['gender', 'race_ethnicity', 'parental_level_of_education', 'lunch', 'test_preparation_course', 'math_score', 'reading_score', 'writing_score', 'total_score']\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   gender                       1000 non-null   object\n",
      " 1   race_ethnicity               1000 non-null   object\n",
      " 2   parental_level_of_education  1000 non-null   object\n",
      " 3   lunch                        1000 non-null   object\n",
      " 4   test_preparation_course      1000 non-null   object\n",
      " 5   math_score                   1000 non-null   int64 \n",
      " 6   reading_score                1000 non-null   int64 \n",
      " 7   writing_score                1000 non-null   int64 \n",
      " 8   total_score                  1000 non-null   int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 70.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the structure of our dataset\n",
    "print(\"Column names in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ed7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing function\n",
    "def preprocess_data(X, y, test_size=0.2, random_state=42):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Create preprocessing pipelines\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "    ])\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ])\n",
    "    \n",
    "    # Fit and transform the data\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "    \n",
    "    return X_train_processed, X_test_processed, y_train, y_test, preprocessor\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics for training data\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    train_adj_r2 = 1 - (1 - train_r2) * (len(y_train) - 1) / (len(y_train) - X_train.shape[1] - 1)\n",
    "    \n",
    "    # Calculate metrics for test data\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_adj_r2 = 1 - (1 - test_r2) * (len(y_test) - 1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "    \n",
    "    return {\n",
    "        'train_mse': train_mse,\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_mae': train_mae,\n",
    "        'train_r2': train_r2,\n",
    "        'train_adj_r2': train_adj_r2,\n",
    "        'test_mse': test_mse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_mae': test_mae,\n",
    "        'test_r2': test_r2,\n",
    "        'test_adj_r2': test_adj_r2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your data\n",
    "# Using math_score as target variable and using other features\n",
    "y = df['math_score']\n",
    "X = df.drop(['math_score'], axis=1)  # Keep reading and writing scores as features\n",
    "\n",
    "# Preprocess the data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42),\n",
    "    'CatBoost': CatBoostRegressor(random_state=42, verbose=False),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6320c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Preprocess data first\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_train_processed, X_test_processed, y_train, y_test, preprocessor \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m results[name] \u001b[38;5;241m=\u001b[39m evaluate_model(model, X_train_processed, X_test_processed, y_train, y_test)\n",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(X, y, test_size, random_state)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create preprocessing pipelines\u001b[39;00m\n\u001b[0;32m     11\u001b[0m numeric_transformer \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     12\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     13\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler())\n\u001b[0;32m     14\u001b[0m ])\n\u001b[0;32m     16\u001b[0m categorical_transformer \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     17\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m, SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m---> 18\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monehot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m     19\u001b[0m ])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Combine preprocessing steps\u001b[39;00m\n\u001b[0;32m     22\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer(\n\u001b[0;32m     23\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     24\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, numeric_transformer, numeric_features),\n\u001b[0;32m     25\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, categorical_transformer, categorical_features)\n\u001b[0;32m     26\u001b[0m     ])\n",
      "\u001b[1;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    # Preprocess data first\n",
    "    X_train_processed, X_test_processed, y_train, y_test, preprocessor = preprocess_data(X, y)\n",
    "    # Evaluate model\n",
    "    results[name] = evaluate_model(model, X_train_processed, X_test_processed, y_train, y_test)\n",
    "    \n",
    "# Create a comparison dataframe\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "metrics = ['test_r2', 'test_rmse', 'test_mae', 'train_r2', 'train_rmse', 'train_mae']\n",
    "comparison_df = comparison_df[metrics]\n",
    "\n",
    "# Display results\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Find the best models based on test R2 score\n",
    "best_models = comparison_df.nlargest(2, 'test_r2')\n",
    "print(\"\\nBest performing models based on Test R2 Score:\")\n",
    "print(best_models[['test_r2', 'test_rmse', 'test_mae']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b36282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "comparison_df['test_r2'].sort_values().plot(kind='bar')\n",
    "plt.title('Model Comparison - Test R² Scores')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize training vs test performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "comparison_df[['train_r2', 'test_r2']].plot(kind='bar', width=0.8)\n",
    "plt.title('Training vs Test R² Scores')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['Training R²', 'Test R²'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25745a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement numypy (from versions: none)\n",
      "ERROR: No matching distribution found for numypy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608dd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
